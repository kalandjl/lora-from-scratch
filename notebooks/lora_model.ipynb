{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "42dbdf5515d74ebe93569a57f0768cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8c4970c14eb4a95ac72835c77f8a5c8",
              "IPY_MODEL_573a7f2dc4b743b6a12af5dc793558d1",
              "IPY_MODEL_79752e1e82e74760a326bb25cea59da7"
            ],
            "layout": "IPY_MODEL_a76edf507ef240849a6455fa0bb3e938"
          }
        },
        "d8c4970c14eb4a95ac72835c77f8a5c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77f09f2487fa4232888dfdd74c72c0e9",
            "placeholder": "​",
            "style": "IPY_MODEL_abe6e78d492544f7b9c63ce27d5ecabf",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "573a7f2dc4b743b6a12af5dc793558d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e516b4d0b56f46c8b53e564bc07d3529",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74f4936168c44a94bff7fdcb5cba1e3b",
            "value": 3
          }
        },
        "79752e1e82e74760a326bb25cea59da7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a4a83e6073e42fda124f8f383692891",
            "placeholder": "​",
            "style": "IPY_MODEL_776eb2f0eff949db9a0ef8674671c3ba",
            "value": " 3/3 [00:00&lt;00:00, 35.29it/s]"
          }
        },
        "a76edf507ef240849a6455fa0bb3e938": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77f09f2487fa4232888dfdd74c72c0e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abe6e78d492544f7b9c63ce27d5ecabf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e516b4d0b56f46c8b53e564bc07d3529": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74f4936168c44a94bff7fdcb5cba1e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a4a83e6073e42fda124f8f383692891": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "776eb2f0eff949db9a0ef8674671c3ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pBUqTe6N8p4q",
        "outputId": "66900a4a-41d4-488f-ddac-f47c9c7e4026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers bitsandbytes accelerate torch tokenizer\n",
        "!pip install -U datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from google.colab import userdata\n",
        "\n",
        "hf_token = userdata.get('COLAB_HF_TOKEN')\n",
        "\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n",
        "\n",
        "# Load the model pass HF secret token\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    token=hf_token,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "print(\"Model loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "42dbdf5515d74ebe93569a57f0768cfa",
            "d8c4970c14eb4a95ac72835c77f8a5c8",
            "573a7f2dc4b743b6a12af5dc793558d1",
            "79752e1e82e74760a326bb25cea59da7",
            "a76edf507ef240849a6455fa0bb3e938",
            "77f09f2487fa4232888dfdd74c72c0e9",
            "abe6e78d492544f7b9c63ce27d5ecabf",
            "e516b4d0b56f46c8b53e564bc07d3529",
            "74f4936168c44a94bff7fdcb5cba1e3b",
            "9a4a83e6073e42fda124f8f383692891",
            "776eb2f0eff949db9a0ef8674671c3ba"
          ]
        },
        "id": "Lr0WnulS9rb8",
        "outputId": "fc5b8620-0a47-475f-c93f-017e0033f192"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42dbdf5515d74ebe93569a57f0768cfa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_text = \"The best part of waking up is\"\n",
        "\n",
        "inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "print(\"\\nTokenized Input IDs:\")\n",
        "print(inputs['input_ids'])\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)\n",
        "\n",
        "logits = outputs.logits\n",
        "\n",
        "print(\"\\nShape of the output logits:\")\n",
        "print(logits.shape)\n",
        "\n",
        "last_token_logits = logits[0, -1, :] # Get logits for the last token in the sequence\n",
        "predicted_token_id = torch.argmax(last_token_logits).item()\n",
        "\n",
        "predicted_word = tokenizer.decode(predicted_token_id)\n",
        "\n",
        "print(f\"\\nModel's next word prediction: '{predicted_word}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OG6F2BRuBOzw",
        "outputId": "e55ff74d-8926-4664-9538-9712ed288930"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenized Input IDs:\n",
            "tensor([[   1,  415, 1489,  744,  302,  275, 1288,  582,  349]])\n",
            "\n",
            "Shape of the output logits:\n",
            "torch.Size([1, 9, 32000])\n",
            "\n",
            "Model's next word prediction: 'coffee'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\n",
        "\n",
        "print(ds[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "m4Zj1yHbDzXN",
        "outputId": "f3e62a67-6b0a-45ec-e3eb-a723664d0260"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'When did Virgin Australia start operating?', 'context': \"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\", 'response': 'Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.', 'category': 'closed_qa'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This one loop will freeze every parameter in the entire model\n",
        "for param in model.parameters():\n",
        "  # \"Freeze\" the model's weight\n",
        "  param.requires_grad = False\n",
        "\n",
        "print(\"--- After freezing ALL layers ---\")\n",
        "print(\"Embedding layer frozen?\", model.model.embed_tokens.weight.requires_grad == False)\n",
        "print(\"Attention layer 15 frozen?\", model.model.layers[15].self_attn.q_proj.weight.requires_grad == False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0nNViDtwG0iG",
        "outputId": "a7e403d2-ecde-4243-ca3e-7d1509957efe"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- After freezing ALL layers ---\n",
            "Embedding layer frozen? True\n",
            "Attention layer 15 frozen? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class LoRALayer(nn.Module):\n",
        "    def __init__(self, original_layer, rank, alpha):\n",
        "        super().__init__()\n",
        "\n",
        "        self.original_layer = original_layer\n",
        "\n",
        "        # Get dimensions from the original layer\n",
        "        in_features = self.original_layer.in_features\n",
        "        out_features = self.original_layer.out_features\n",
        "\n",
        "        # Initialize LoRA A & B matrices\n",
        "        self.lora_A = nn.Parameter(torch.randn(in_features, rank))\n",
        "        self.lora_B = nn.Parameter(torch.zeros(rank, out_features)) # Paper initializes B with zeros\n",
        "\n",
        "        # Initialize A with Kaiming uniform for better stability\n",
        "        nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))\n",
        "\n",
        "        # Scaling factor\n",
        "        self.scaling = alpha / rank\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # The origin linear layer calculation\n",
        "        original_output = self.original_layer(x)\n",
        "\n",
        "        # New update w/A & B matrices\n",
        "        lora_update = (x @ self.lora_A @ self.lora_B) * self.scaling\n",
        "\n",
        "        return original_output + lora_update"
      ],
      "metadata": {
        "id": "u1a9dz2dNb9O"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modules = model.model.layers\n",
        "\n",
        "for module in modules:\n",
        "\n",
        "  # rank and alpha variables for LoRA layers\n",
        "  r = 8\n",
        "  a = 16\n",
        "\n",
        "  self_attn = module.self_attn\n",
        "  self_attn.q_proj = LoRALayer(self_attn.q_proj, r, a)\n",
        "  self_attn.v_proj = LoRALayer(self_attn.v_proj, r, a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuepQ9MQOIOa",
        "outputId": "96a5faae-16ea-4a3b-9c80-32e434703753"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n",
            "Linear(in_features=4096, out_features=4096, bias=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BH0PMrokRgx7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}